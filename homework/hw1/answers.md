# 1
Supervised learning, prob. classification (over accident / not accident)
Supervised learning, classification (over cars / cyclists / pedestrians)
Supervised learning, prob. classification (over stop / not stop)
Unsupervised learning

# 2
While it has a benefit towards the goodness of fit, it is more critical to understand whether the model generalizes or not, from a practical point of view, since that will indicate whether its preditictions will be practically of use.
Usually, overfit. The model is too flexible (too many degrees of freedom) over data, and captures not only the underlying trend but also noise wiggling, which is the kind of information that the model should try to minimize learning from, rather than follow. This leads to good fit over data, but then bad fit over test set, where the noise in x is recognised as information, that is the predictor varies consideraly with noise (small) variations on the features.

# 3
